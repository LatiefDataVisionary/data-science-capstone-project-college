{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxJSTMJ+VX0DuZ64UpuDs0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LatiefDataVisionary/data-science-capstone-project-college/blob/main/notebooks/02_eda_raw_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a188906"
      },
      "source": [
        "# **Exploratory Data Analysis of Raw Spotify Reviews**\n",
        "\n",
        "This notebook performs an initial Exploratory Data Analysis (EDA) on the raw dataset of Spotify app reviews. The goal is to understand the basic structure, quality, and characteristics of the data before any preprocessing steps are applied."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32aaa695"
      },
      "source": [
        "## **1. Setup and Library Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf0a1ad9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Set plot style\n",
        "sns.set_style('whitegrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b8ef499"
      },
      "source": [
        "## **2. Data Loading and Initial Inspection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd6f8abb"
      },
      "source": [
        "Loading the dataset from the specified CSV file into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# English comment dataset\n",
        "data_en_1 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_en_au_1.csv'\n",
        "data_en_2 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_en_au_2.csv'\n",
        "data_en_3 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_en_uk_1.csv'\n",
        "data_en_4 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_en_uk_2.csv'\n",
        "data_en_5 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_en_us_1.csv'\n",
        "data_en_6 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_en_us_2.csv'\n",
        "\n",
        "# Indonesian comment dataset\n",
        "data_id_1 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_id_id_1.csv'\n",
        "data_id_2 = 'https://raw.githubusercontent.com/LatiefDataVisionary/data-science-capstone-project-college/refs/heads/main/data/raw/spotify_reviews_id_id_2.csv'"
      ],
      "metadata": {
        "id": "WCrBJswMc4o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty lists to store dataframes\n",
        "en_dfs = []\n",
        "id_dfs = []"
      ],
      "metadata": {
        "id": "NoT7DNTpq1-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of English data file paths\n",
        "english_files = [data_en_1, data_en_2, data_en_3, data_en_4, data_en_5, data_en_6]\n",
        "\n",
        "# Iterate through English files and load them\n",
        "for file_path in english_files:\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        en_dfs.append(df)\n",
        "        print(f\"Successfully loaded {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file_path} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "\n",
        "# Concatenate English dataframes\n",
        "if en_dfs:\n",
        "    raw_en_df = pd.concat(en_dfs, ignore_index=True)\n",
        "    print(f\"\\nEnglish dataset loaded successfully with {len(raw_en_df)} reviews.\")\n",
        "else:\n",
        "    raw_en_df = None\n",
        "    print(\"\\nNo English dataframes were loaded.\")"
      ],
      "metadata": {
        "id": "WRdT8jsApkSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Indonesian data file paths\n",
        "indonesian_files = [data_id_1, data_id_2]\n",
        "\n",
        "# Iterate through Indonesian files and load them\n",
        "for file_path in indonesian_files:\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        id_dfs.append(df)\n",
        "        print(f\"Successfully loaded {file_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file_path} not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "\n",
        "# Concatenate Indonesian dataframes\n",
        "if id_dfs:\n",
        "    raw_id_df = pd.concat(id_dfs, ignore_index=True)\n",
        "    print(f\"\\nIndonesian dataset loaded successfully with {len(raw_id_df)} reviews.\")\n",
        "else:\n",
        "    raw_id_df = None\n",
        "    print(\"\\nNo Indonesian dataframes were loaded.\")"
      ],
      "metadata": {
        "id": "Ot77bBn_qnWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fdfddea"
      },
      "source": [
        "Displaying the first 5 rows of the DataFrame to get a glimpse of the data structure and content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "624993d8"
      },
      "source": [
        "if raw_en_df is not None:\n",
        "    print(\"First 5 rows of English Reviews DataFrame (raw_en_df):\")\n",
        "    display(raw_en_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if raw_id_df is not None:\n",
        "    print(\"\\nFirst 5 rows of Indonesian Reviews DataFrame (raw_id_df):\")\n",
        "    display(raw_id_df.head())"
      ],
      "metadata": {
        "id": "yz7vfMTgp4o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdd9cca7"
      },
      "source": [
        "Printing concise information about the DataFrame, including the index dtype and column dtypes, non-null values, and memory usage. This helps in understanding the data types and identifying potential missing values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if raw_id_df is not None:\n",
        "    print(\"\\nThe informaton of English Reviews DataFrame (raw_enn_df):\")\n",
        "    display(raw_en_df.info())"
      ],
      "metadata": {
        "id": "cAzFmsxcqW8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17c02fb7"
      },
      "source": [
        "if raw_id_df is not None:\n",
        "    print(\"\\nThe informaiton of Indonesian Reviews DataFrame (raw_id_df):\")\n",
        "    display(raw_id_df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d159f5"
      },
      "source": [
        "Generating descriptive statistics for both the numerical and categorical columns in the DataFrame. This provides insights into the central tendency, dispersion, and shape of the distribution of numerical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65e9512e"
      },
      "source": [
        "if raw_en_df is not None:\n",
        "    print(\"Descriptive statistics for English Reviews DataFrame (raw_en_df):\")\n",
        "    display(raw_en_df.describe(include='all'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if raw_id_df is not None:\n",
        "    print(\"\\nDescriptive statistics for Indonesian Reviews DataFrame (raw_id_df):\")\n",
        "    display(raw_id_df.describe(include='all'))"
      ],
      "metadata": {
        "id": "jmTX60s3qjf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ec13bfb"
      },
      "source": [
        "## 3. Data Quality Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c89375d4"
      },
      "source": [
        "Checking for missing values in each column and summing them up to get a total count of missing entries per column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cc30501"
      },
      "source": [
        "if raw_df is not None:\n",
        "    missing_values = raw_df.isnull().sum()\n",
        "    print(\"Missing values per column:\")\n",
        "    print(missing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f84f4e8"
      },
      "source": [
        "Checking for and counting duplicate rows in the DataFrame. Duplicate rows can skew analysis and should be identified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edabb05d"
      },
      "source": [
        "if raw_df is not None:\n",
        "    duplicate_rows = raw_df.duplicated().sum()\n",
        "    print(f\"\\nNumber of duplicate rows: {duplicate_rows}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5732ff17"
      },
      "source": [
        "**Summary of Data Quality:**\n",
        "\n",
        "Based on the checks above:\n",
        "- We can see the number of missing values in each column.\n",
        "- We have identified the total count of duplicate rows.\n",
        "\n",
        "This initial assessment helps us understand the cleanliness of the raw data and highlights areas that may require attention during preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a07ef762"
      },
      "source": [
        "## 4. Analysis of Review Ratings (score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db0a21f2"
      },
      "source": [
        "Visualizing the distribution of review scores using a count plot to understand the frequency of each rating (1 to 5 stars)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a693e1a8"
      },
      "source": [
        "if raw_df is not None:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(data=raw_df, x='score', palette='viridis')\n",
        "    plt.title('Distribution of Review Scores')\n",
        "    plt.xlabel('Score')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877a09a2"
      },
      "source": [
        "**Analysis of Score Distribution:**\n",
        "\n",
        "The count plot reveals the distribution of star ratings. We can observe which scores are most frequent. This gives us an initial idea of the overall sentiment of the reviews and the balance of the dataset. For example, if one score significantly outweighs others, the dataset is skewed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dd97e0b"
      },
      "source": [
        "## 5. Analysis of Review Text (content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c557b5c2"
      },
      "source": [
        "### Subsection 5.1: Review Length Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0014af1"
      },
      "source": [
        "Creating new columns for character length and word count of each review in the `content` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffde927d"
      },
      "source": [
        "if raw_df is not None and 'content' in raw_df.columns:\n",
        "    raw_df['char_length'] = raw_df['content'].astype(str).apply(len)\n",
        "    raw_df['word_count'] = raw_df['content'].astype(str).apply(lambda x: len(x.split()))\n",
        "    print(\"Character length and word count columns added.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85d57105"
      },
      "source": [
        "Generating histograms to visualize the distribution of review lengths based on character count and word count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b8bbc25"
      },
      "source": [
        "if raw_df is not None and 'char_length' in raw_df.columns and 'word_count' in raw_df.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    sns.histplot(data=raw_df, x='char_length', bins=50, ax=axes[0], kde=True)\n",
        "    axes[0].set_title('Distribution of Review Character Length')\n",
        "    axes[0].set_xlabel('Character Length')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "\n",
        "    sns.histplot(data=raw_df, x='word_count', bins=50, ax=axes[1], kde=True)\n",
        "    axes[1].set_title('Distribution of Review Word Count')\n",
        "    axes[1].set_xlabel('Word Count')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "215c72fa"
      },
      "source": [
        "**Analysis of Review Length:**\n",
        "\n",
        "The histograms show the distribution of how long reviews are, both in terms of the number of characters and the number of words. This helps us understand the typical length of reviews and identify any outliers (very short or very long reviews). Most reviews appear to be concentrated within a certain range of words/characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f1d0475"
      },
      "source": [
        "### Subsection 5.2: Word Cloud of Raw Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61fbe68e"
      },
      "source": [
        "Generating a Word Cloud from the raw review text to visually represent the most frequent words. Note that this is based on unprocessed text and will include stopwords and other noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "330b45b0"
      },
      "source": [
        "if raw_df is not None and 'content' in raw_df.columns:\n",
        "    # Combine all reviews into a single string\n",
        "    all_reviews = \" \".join(review for review in raw_df['content'].astype(str))\n",
        "\n",
        "    # Generate word cloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_reviews)\n",
        "\n",
        "    # Display the word cloud\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('Word Cloud of Raw Review Text')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a466de4"
      },
      "source": [
        "**Analysis of Word Cloud:**\n",
        "\n",
        "The word cloud provides a quick visual overview of the most frequently occurring words in the raw review text. As expected with unprocessed text, it contains many common words (stopwords) and potential noise. However, it gives a raw first impression of the dominant themes and keywords present in the reviews before any cleaning or preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac1b1d0c"
      },
      "source": [
        "## 6. Temporal Analysis (Review Timestamps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74858484"
      },
      "source": [
        "Converting the `at` column to a datetime object to enable time-based analysis. Errors in conversion will be coerced to `NaT` (Not a Time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0feee6e6"
      },
      "source": [
        "if raw_df is not None and 'at' in raw_df.columns:\n",
        "    raw_df['at'] = pd.to_datetime(raw_df['at'], errors='coerce')\n",
        "    print(\" 'at' column converted to datetime objects.\")\n",
        "    # Drop rows where datetime conversion failed\n",
        "    raw_df.dropna(subset=['at'], inplace=True)\n",
        "    print(f\"Dropped rows with invalid datetime values. Remaining rows: {len(raw_df)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e1839b5"
      },
      "source": [
        "Plotting the number of reviews submitted over time, grouped by month, to identify any trends or patterns in review activity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9b6337a"
      },
      "source": [
        "if raw_df is not None and 'at' in raw_df.columns:\n",
        "    # Extract month and year\n",
        "    raw_df['review_month'] = raw_df['at'].dt.to_period('M')\n",
        "\n",
        "    # Group by month and count reviews\n",
        "    monthly_reviews = raw_df.groupby('review_month').size()\n",
        "\n",
        "    # Plot the time series\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    monthly_reviews.plot()\n",
        "    plt.title('Number of Reviews Over Time (Monthly)')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72edabe6"
      },
      "source": [
        "**Analysis of Temporal Trends:**\n",
        "\n",
        "The time series plot shows how the number of reviews has changed over the months. We can observe trends such as periods of increased or decreased review activity. Spikes in reviews might correlate with significant events like app updates, marketing campaigns, or service outages. A general upward or downward trend could indicate changes in user engagement over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a8ea2bd"
      },
      "source": [
        "## 7. Conclusion & Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df37b90f"
      },
      "source": [
        "**Conclusion:**\n",
        "\n",
        "This initial EDA on the raw Spotify reviews dataset has provided valuable insights into its structure, quality, and content. We have examined:\n",
        "- The dataset's basic information and structure.\n",
        "- The presence of missing values and duplicate rows.\n",
        "- The distribution of review scores, indicating the overall sentiment.\n",
        "- The characteristics of the review text, including length and the most frequent raw words.\n",
        "- The temporal trends in review submission.\n",
        "\n",
        "The raw text data, as seen in the word cloud, is noisy and requires significant cleaning and preprocessing before it can be effectively used for tasks like sentiment analysis or topic modeling.\n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "The logical next step in this project, which will be covered in the notebook `03_data_preprocessing_and_cleaning.ipynb`, is to clean and preprocess the raw text data. This will involve steps such as:\n",
        "- Handling missing values and duplicate rows (if not already done).\n",
        "- Text cleaning (e.g., removing punctuation, special characters, numbers).\n",
        "- Lowercasing the text.\n",
        "- Tokenization.\n",
        "- Removing stopwords.\n",
        "- Stemming or lemmatization.\n",
        "- Handling bilingual text (if necessary).\n",
        "\n",
        "These preprocessing steps are crucial to transform the raw review text into a format suitable for further analysis and machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XYTGOE9AkAZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3f37168"
      },
      "source": [
        "# Task\n",
        "Generate the complete code and markdown text for a Jupyter Notebook named 02_eda_raw_data.ipynb to perform a comprehensive Exploratory Data Analysis (EDA) on raw, unprocessed bilingual (English and Indonesian) Spotify app reviews. The dataset consists of multiple CSV files for each language located in \"../data/raw/\". The notebook should include sections for setup, data loading and initial inspection, data quality check, analysis of review ratings, analysis of review text (including length and word clouds), temporal analysis, and a conclusion summarizing findings and outlining next steps. The entire output, including titles, explanations, variable names, and comments, must be in English. The analysis should be performed for both English and Indonesian reviews, using separate dataframes (`raw_en_df` and `raw_id_df`) where appropriate, and the code should handle potential errors during data loading and processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f869017"
      },
      "source": [
        "## Modify data loading\n",
        "\n",
        "### Subtask:\n",
        "Update the data loading cell to load the English and Indonesian datasets into `raw_en_df` and `raw_id_df` DataFrames respectively, concatenating the multiple files for each language. Handle potential errors during loading.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f50d298"
      },
      "source": [
        "## Modify initial inspection\n",
        "\n",
        "### Subtask:\n",
        "Update the initial inspection cells (`.head()`, `.info()`, `.describe()`) to display information for both `raw_en_df` and `raw_id_df`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "429b8d37"
      },
      "source": [
        "## Modify data quality check\n",
        "\n",
        "### Subtask:\n",
        "Update the data quality check cells (missing values and duplicates) to perform checks on both `raw_en_df` and `raw_id_df`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82fbb4b7"
      },
      "source": [
        "**Reasoning**:\n",
        "Update the code to check for missing values and duplicate rows in both `raw_en_df` and `raw_id_df` and print the results with clear labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84e38dad"
      },
      "source": [
        "if raw_en_df is not None:\n",
        "    print(\"Missing values per column (English dataset - raw_en_df):\")\n",
        "    missing_values_en = raw_en_df.isnull().sum()\n",
        "    print(missing_values_en)\n",
        "\n",
        "if raw_id_df is not None:\n",
        "    print(\"\\nMissing values per column (Indonesian dataset - raw_id_df):\")\n",
        "    missing_values_id = raw_id_df.isnull().sum()\n",
        "    print(missing_values_id)\n",
        "\n",
        "if raw_en_df is not None:\n",
        "    duplicate_rows_en = raw_en_df.duplicated().sum()\n",
        "    print(f\"\\nNumber of duplicate rows (English dataset - raw_en_df): {duplicate_rows_en}\")\n",
        "\n",
        "if raw_id_df is not None:\n",
        "    duplicate_rows_id = raw_id_df.duplicated().sum()\n",
        "    print(f\"Number of duplicate rows (Indonesian dataset - raw_id_df): {duplicate_rows_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76e30188"
      },
      "source": [
        "## Modify analysis of review ratings\n",
        "\n",
        "### Subtask:\n",
        "Update the score distribution analysis and plotting to visualize the distribution for both English and Indonesian reviews, potentially on separate plots or a combined plot with language as a differentiator.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e9fbfe5"
      },
      "source": [
        "**Reasoning**:\n",
        "Update the score distribution analysis by combining the English and Indonesian dataframes and plotting the score distribution for both languages on the same plot using 'language' as a hue.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9d7e3d8"
      },
      "source": [
        "if raw_en_df is not None and raw_id_df is not None and 'score' in raw_en_df.columns and 'score' in raw_id_df.columns:\n",
        "    # Add a language column to differentiate between English and Indonesian reviews\n",
        "    raw_en_df['language'] = 'English'\n",
        "    raw_id_df['language'] = 'Indonesian'\n",
        "\n",
        "    # Combine the dataframes\n",
        "    combined_df = pd.concat([raw_en_df, raw_id_df], ignore_index=True)\n",
        "\n",
        "    # Create the count plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(data=combined_df, x='score', hue='language', palette='viridis')\n",
        "    plt.title('Distribution of Review Scores by Language')\n",
        "    plt.xlabel('Score')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.show()\n",
        "elif raw_en_df is not None and 'score' in raw_en_df.columns:\n",
        "    print(\"Only English data available. Plotting English score distribution.\")\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(data=raw_en_df, x='score', palette='viridis')\n",
        "    plt.title('Distribution of English Review Scores')\n",
        "    plt.xlabel('Score')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.show()\n",
        "elif raw_id_df is not None and 'score' in raw_id_df.columns:\n",
        "    print(\"Only Indonesian data available. Plotting Indonesian score distribution.\")\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(data=raw_id_df, x='score', palette='viridis')\n",
        "    plt.title('Distribution of Indonesian Review Scores')\n",
        "    plt.xlabel('Score')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Score data is not available in either dataframe for plotting.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23b8273"
      },
      "source": [
        "## Modify analysis of review text\n",
        "\n",
        "### Subtask:\n",
        "Update the analysis of review text to include review length analysis (character length and word count) and word cloud generation for both English and Indonesian reviews.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99abb8b6"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate character length and word count for both English and Indonesian dataframes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19278984"
      },
      "source": [
        "if raw_en_df is not None and 'content' in raw_en_df.columns:\n",
        "    raw_en_df['char_length'] = raw_en_df['content'].astype(str).apply(len)\n",
        "    raw_en_df['word_count'] = raw_en_df['content'].astype(str).apply(lambda x: len(x.split()))\n",
        "    print(\"Character length and word count columns added to raw_en_df.\")\n",
        "else:\n",
        "    print(\"raw_en_df is None or 'content' column not found in raw_en_df. Cannot add length/count columns.\")\n",
        "\n",
        "if raw_id_df is not None and 'content' in raw_id_df.columns:\n",
        "    raw_id_df['char_length'] = raw_id_df['content'].astype(str).apply(len)\n",
        "    raw_id_df['word_count'] = raw_id_df['content'].astype(str).apply(lambda x: len(x.split()))\n",
        "    print(\"Character length and word count columns added to raw_id_df.\")\n",
        "else:\n",
        "    print(\"raw_id_df is None or 'content' column not found in raw_id_df. Cannot add length/count columns.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c678a82"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate histograms to visualize the distribution of character length and word count for both English and Indonesian reviews using subplots.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58160d20"
      },
      "source": [
        "if raw_en_df is not None and 'char_length' in raw_en_df.columns and 'word_count' in raw_en_df.columns and \\\n",
        "   raw_id_df is not None and 'char_length' in raw_id_df.columns and 'word_count' in raw_id_df.columns:\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    sns.histplot(data=raw_en_df, x='char_length', bins=50, ax=axes[0, 0], kde=True, color='skyblue')\n",
        "    axes[0, 0].set_title('Distribution of English Review Character Length')\n",
        "    axes[0, 0].set_xlabel('Character Length')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "    sns.histplot(data=raw_en_df, x='word_count', bins=50, ax=axes[0, 1], kde=True, color='salmon')\n",
        "    axes[0, 1].set_title('Distribution of English Review Word Count')\n",
        "    axes[0, 1].set_xlabel('Word Count')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "    sns.histplot(data=raw_id_df, x='char_length', bins=50, ax=axes[1, 0], kde=True, color='skyblue')\n",
        "    axes[1, 0].set_title('Distribution of Indonesian Review Character Length')\n",
        "    axes[1, 0].set_xlabel('Character Length')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "\n",
        "    sns.histplot(data=raw_id_df, x='word_count', bins=50, ax=axes[1, 1], kde=True, color='salmon')\n",
        "    axes[1, 1].set_title('Distribution of Indonesian Review Word Count')\n",
        "    axes[1, 1].set_xlabel('Word Count')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "elif raw_en_df is not None and 'char_length' in raw_en_df.columns and 'word_count' in raw_en_df.columns:\n",
        "    print(\"Only English data available. Plotting English review length distributions.\")\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    sns.histplot(data=raw_en_df, x='char_length', bins=50, ax=axes[0], kde=True, color='skyblue')\n",
        "    axes[0].set_title('Distribution of English Review Character Length')\n",
        "    axes[0].set_xlabel('Character Length')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    sns.histplot(data=raw_en_df, x='word_count', bins=50, ax=axes[1], kde=True, color='salmon')\n",
        "    axes[1].set_title('Distribution of English Review Word Count')\n",
        "    axes[1].set_xlabel('Word Count')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "elif raw_id_df is not None and 'char_length' in raw_id_df.columns and 'word_count' in raw_id_df.columns:\n",
        "    print(\"Only Indonesian data available. Plotting Indonesian review length distributions.\")\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    sns.histplot(data=raw_id_df, x='char_length', bins=50, ax=axes[0], kde=True, color='skyblue')\n",
        "    axes[0].set_title('Distribution of Indonesian Review Character Length')\n",
        "    axes[0].set_xlabel('Character Length')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    sns.histplot(data=raw_id_df, x='word_count', bins=50, ax=axes[1], kde=True, color='salmon')\n",
        "    axes[1].set_title('Distribution of Indonesian Review Word Count')\n",
        "    axes[1].set_xlabel('Word Count')\n",
        "    axes[1].set_ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Review length data is not available in either dataframe for plotting.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "476344f4"
      },
      "source": [
        "**Reasoning**:\n",
        "Generate and display separate word clouds for the raw review content of English and Indonesian dataframes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af1a9f98"
      },
      "source": [
        "if raw_en_df is not None and 'content' in raw_en_df.columns:\n",
        "    # Combine all English reviews into a single string\n",
        "    all_en_reviews = \" \".join(review for review in raw_en_df['content'].astype(str))\n",
        "\n",
        "    # Generate English word cloud\n",
        "    wordcloud_en = WordCloud(width=800, height=400, background_color='white').generate(all_en_reviews)\n",
        "\n",
        "    # Display the English word cloud\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(wordcloud_en, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('Word Cloud of Raw English Review Text')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"raw_en_df is None or 'content' column not found in raw_en_df. Cannot generate English word cloud.\")\n",
        "\n",
        "\n",
        "if raw_id_df is not None and 'content' in raw_id_df.columns:\n",
        "    # Combine all Indonesian reviews into a single string\n",
        "    all_id_reviews = \" \".join(review for review in raw_id_df['content'].astype(str))\n",
        "\n",
        "    # Generate Indonesian word cloud\n",
        "    wordcloud_id = WordCloud(width=800, height=400, background_color='white').generate(all_id_reviews)\n",
        "\n",
        "    # Display the Indonesian word cloud\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(wordcloud_id, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title('Word Cloud of Raw Indonesian Review Text')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"raw_id_df is None or 'content' column not found in raw_id_df. Cannot generate Indonesian word cloud.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19b67321"
      },
      "source": [
        "## Modify temporal analysis\n",
        "\n",
        "### Subtask:\n",
        "Update the temporal analysis to plot the number of reviews over time for both English and Indonesian datasets, potentially on the same plot with different lines/colors or on separate subplots.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12fd9696"
      },
      "source": [
        "**Reasoning**:\n",
        "Check for dataframe existence and 'at' column, convert 'at' to datetime, drop NaT rows, extract month, group by month and count reviews for both dataframes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08d6bb82"
      },
      "source": [
        "if raw_en_df is not None and 'at' in raw_en_df.columns:\n",
        "    raw_en_df['at'] = pd.to_datetime(raw_en_df['at'], errors='coerce')\n",
        "    raw_en_df.dropna(subset=['at'], inplace=True)\n",
        "    raw_en_df['review_month'] = raw_en_df['at'].dt.to_period('M')\n",
        "    monthly_reviews_en = raw_en_df.groupby('review_month').size()\n",
        "    print(f\"English reviews processed. Remaining rows: {len(raw_en_df)}\")\n",
        "else:\n",
        "    monthly_reviews_en = None\n",
        "    print(\"raw_en_df is None or 'at' column not found in raw_en_df. Cannot process English temporal data.\")\n",
        "\n",
        "if raw_id_df is not None and 'at' in raw_id_df.columns:\n",
        "    raw_id_df['at'] = pd.to_datetime(raw_id_df['at'], errors='coerce')\n",
        "    raw_id_df.dropna(subset=['at'], inplace=True)\n",
        "    raw_id_df['review_month'] = raw_id_df['at'].dt.to_period('M')\n",
        "    monthly_reviews_id = raw_id_df.groupby('review_month').size()\n",
        "    print(f\"Indonesian reviews processed. Remaining rows: {len(raw_id_df)}\")\n",
        "else:\n",
        "    monthly_reviews_id = None\n",
        "    print(\"raw_id_df is None or 'at' column not found in raw_id_df. Cannot process Indonesian temporal data.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6dc21a5"
      },
      "source": [
        "**Reasoning**:\n",
        "Plot the monthly review counts for both English and Indonesian reviews on the same plot, adding title, labels, legend, and rotating x-axis ticks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71f3c629"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "if monthly_reviews_en is not None:\n",
        "    monthly_reviews_en.plot(label='English Reviews')\n",
        "\n",
        "if monthly_reviews_id is not None:\n",
        "    monthly_reviews_id.plot(label='Indonesian Reviews')\n",
        "\n",
        "if monthly_reviews_en is not None or monthly_reviews_id is not None:\n",
        "    plt.title('Number of Reviews Over Time (Monthly) by Language')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Number of Reviews')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No temporal review data available for plotting.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeddebd4"
      },
      "source": [
        "## Modify conclusion\n",
        "\n",
        "### Subtask:\n",
        "Update the conclusion to summarize the findings for both English and Indonesian datasets and reiterate the next steps for cleaning and preprocessing, acknowledging the bilingual nature of the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ccbb665"
      },
      "source": [
        "**Reasoning**:\n",
        "Update the conclusion markdown cell to summarize the findings for both English and Indonesian datasets and reiterate the next steps, acknowledging the bilingual nature of the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c0be9e6"
      },
      "source": [
        "# This is a markdown cell, the content will be updated directly in the notebook.\n",
        "# No Python code is needed here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2a48bdc"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The English dataset contains 155,000 reviews and the Indonesian dataset contains 65,000 reviews. Both datasets have 11 columns.\n",
        "*   Both English and Indonesian datasets have missing values in the `content`, `reviewCreatedVersion`, `replyContent`, `repliedAt`, and `appVersion` columns, with varying extents of missingness between the languages.\n",
        "*   Significant numbers of duplicate rows were found in both datasets: 77922 in the English dataset and 5754 in the Indonesian dataset.\n",
        "*   The average review score is slightly higher for Indonesian reviews (4.34) compared to English reviews (4.21).\n",
        "*   The distribution of `thumbsUpCount` is highly skewed in both languages, with most reviews having zero likes.\n",
        "*   Review length analysis showed the distributions of character length and word count for both English and Indonesian reviews.\n",
        "*   Temporal analysis revealed the monthly trend of review submissions for both languages.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Address the significant number of duplicate rows in both datasets during the data cleaning phase.\n",
        "*   Develop a strategy to handle missing values, particularly in columns like `replyContent` and `repliedAt`, which have a high percentage of missing data.\n"
      ]
    }
  ]
}